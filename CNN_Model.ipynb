{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer les librairies pours utiliser un CNN\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.models import Input\n",
    "import keras.layers as layers\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer les données de training et test\n",
    "trainData = pd.read_csv('Data/train.csv')\n",
    "trainLabels = pd.read_csv('Data/train_result.csv')\n",
    "testData = pd.read_csv('Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mettre les points en bas de 0 à 0 et enlver les NaN\n",
    "trainData[trainData < 0] = 0\n",
    "trainData = trainData.dropna(axis=1)\n",
    "\n",
    "testData[testData < 0] = 0\n",
    "testData = testData[trainData.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformer les donnees pour avoir une matrice de 4d pour que l'entree dans le CNN soit en 3d\n",
    "newTrainData = np.array(trainData).reshape(50000,28,56,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Créer les données de training et validation\n",
    "trainX,validX,trainY,validY = train_test_split(newTrainData,trainLabels,test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualiser\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(trainX[15])\n",
    "trainY.iloc[15,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer les labels en one hot vector\n",
    "labels = trainLabels.iloc[:,1].unique().size\n",
    "trainYOH = keras.utils.to_categorical(trainY['Class'], labels)\n",
    "validYOH = keras.utils.to_categorical(validY['Class'], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batir le CNN\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28,56,1)))\n",
    "model.add(layers.AveragePooling2D())\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "model.add(layers.Dense(units=19, activation = 'softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparametre d'entrainement\n",
    "batchSize = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 2.2591 - accuracy: 0.2439 - val_loss: 1.5565 - val_accuracy: 0.4918\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 1.1028 - accuracy: 0.6504 - val_loss: 0.7816 - val_accuracy: 0.7595\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.6307 - accuracy: 0.8056 - val_loss: 0.5593 - val_accuracy: 0.8299\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.4491 - accuracy: 0.8648 - val_loss: 0.4442 - val_accuracy: 0.8610\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.3544 - accuracy: 0.8927 - val_loss: 0.4013 - val_accuracy: 0.8762\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.3002 - accuracy: 0.9092 - val_loss: 0.3650 - val_accuracy: 0.8887\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.2596 - accuracy: 0.9197 - val_loss: 0.3413 - val_accuracy: 0.8953\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.2238 - accuracy: 0.9318 - val_loss: 0.3181 - val_accuracy: 0.9035\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.1986 - accuracy: 0.9389 - val_loss: 0.3057 - val_accuracy: 0.9104\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.1761 - accuracy: 0.9444 - val_loss: 0.2889 - val_accuracy: 0.9125\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 13s 40ms/step - loss: 0.1523 - accuracy: 0.9532 - val_loss: 0.2860 - val_accuracy: 0.9166\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.1371 - accuracy: 0.9562 - val_loss: 0.2776 - val_accuracy: 0.9190\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.1200 - accuracy: 0.9623 - val_loss: 0.2893 - val_accuracy: 0.9202\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.1081 - accuracy: 0.9650 - val_loss: 0.2944 - val_accuracy: 0.9191\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.0943 - accuracy: 0.9704 - val_loss: 0.2847 - val_accuracy: 0.9244\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.0848 - accuracy: 0.9731 - val_loss: 0.2911 - val_accuracy: 0.9218\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.0725 - accuracy: 0.9768 - val_loss: 0.2998 - val_accuracy: 0.9245\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 0.0653 - accuracy: 0.9786 - val_loss: 0.2978 - val_accuracy: 0.9254\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.0573 - accuracy: 0.9812 - val_loss: 0.3141 - val_accuracy: 0.9229\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.0525 - accuracy: 0.9822 - val_loss: 0.3184 - val_accuracy: 0.9261\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.0458 - accuracy: 0.9842 - val_loss: 0.3296 - val_accuracy: 0.9264\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.0469 - accuracy: 0.9836 - val_loss: 0.3306 - val_accuracy: 0.9262\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 12s 40ms/step - loss: 0.0423 - accuracy: 0.9851 - val_loss: 0.3516 - val_accuracy: 0.9206\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.0335 - accuracy: 0.9890 - val_loss: 0.3473 - val_accuracy: 0.9266\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 0.0296 - accuracy: 0.9901 - val_loss: 0.3621 - val_accuracy: 0.9235\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 0.3624 - val_accuracy: 0.9270\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 0.0322 - accuracy: 0.9888 - val_loss: 0.3728 - val_accuracy: 0.9276\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.3720 - val_accuracy: 0.9272\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 13s 40ms/step - loss: 0.0276 - accuracy: 0.9905 - val_loss: 0.3877 - val_accuracy: 0.9235\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 12s 40ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.3852 - val_accuracy: 0.9268\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 0.0231 - accuracy: 0.9918 - val_loss: 0.4365 - val_accuracy: 0.9180\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 0.0208 - accuracy: 0.9926 - val_loss: 0.4159 - val_accuracy: 0.9230\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 0.4020 - val_accuracy: 0.9310\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.4132 - val_accuracy: 0.9246\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.4224 - val_accuracy: 0.9279\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.4070 - val_accuracy: 0.9294\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 0.3967 - val_accuracy: 0.9293\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.4067 - val_accuracy: 0.9319\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.3941 - val_accuracy: 0.9329\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.3943 - val_accuracy: 0.9325\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.3990 - val_accuracy: 0.9328\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 0.4429 - val_accuracy: 0.9264\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.4116 - val_accuracy: 0.9287\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.4129 - val_accuracy: 0.9334\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.4501 - val_accuracy: 0.9271\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.4229 - val_accuracy: 0.9313\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.4534 - val_accuracy: 0.9272\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 13s 40ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.4125 - val_accuracy: 0.9338\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 13s 40ms/step - loss: 0.0198 - accuracy: 0.9929 - val_loss: 0.4155 - val_accuracy: 0.9308\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.3896 - val_accuracy: 0.9401\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.3991 - val_accuracy: 0.9389\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.4193 - val_accuracy: 0.9369\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.5212 - val_accuracy: 0.9172\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.4115 - val_accuracy: 0.9330\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.4054 - val_accuracy: 0.9372\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.4069 - val_accuracy: 0.9348\n",
      "Epoch 57/100\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.4346 - val_accuracy: 0.9329\n",
      "Epoch 58/100\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.4556 - val_accuracy: 0.9304\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.4349 - val_accuracy: 0.9317\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 14s 43ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.3975 - val_accuracy: 0.9360\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.3841 - val_accuracy: 0.9414\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.4013 - val_accuracy: 0.9386\n",
      "Epoch 63/100\n",
      "313/313 [==============================] - 17s 53ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.4064 - val_accuracy: 0.9354\n",
      "Epoch 64/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.3810 - val_accuracy: 0.9400\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.4091 - val_accuracy: 0.9358\n",
      "Epoch 66/100\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.3897 - val_accuracy: 0.9410\n",
      "Epoch 67/100\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.3723 - val_accuracy: 0.9445\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 4.9825e-04 - accuracy: 0.9999 - val_loss: 0.3750 - val_accuracy: 0.9462\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - 17s 54ms/step - loss: 1.6225e-04 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.9466\n",
      "Epoch 70/100\n",
      "313/313 [==============================] - 15s 49ms/step - loss: 9.9080e-05 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9462\n",
      "Epoch 71/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 7.9645e-05 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.9466\n",
      "Epoch 72/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 6.6935e-05 - accuracy: 1.0000 - val_loss: 0.3872 - val_accuracy: 0.9465\n",
      "Epoch 73/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 5.7228e-05 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.9468\n",
      "Epoch 74/100\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 4.9618e-05 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9472\n",
      "Epoch 75/100\n",
      "313/313 [==============================] - 16s 52ms/step - loss: 4.2974e-05 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9469\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 3.7591e-05 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9474\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 3.2801e-05 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9471\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 2.8691e-05 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.9471\n",
      "Epoch 79/100\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 2.4990e-05 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.9470\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 2.1871e-05 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9470\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 1.9138e-05 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.9469\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - 14s 46ms/step - loss: 1.6641e-05 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.9465\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - 15s 49ms/step - loss: 1.4555e-05 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.9465\n",
      "Epoch 84/100\n",
      "313/313 [==============================] - 14s 45ms/step - loss: 1.2648e-05 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9465\n",
      "Epoch 85/100\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.0982e-05 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9462\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 9.5311e-06 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.9457\n",
      "Epoch 87/100\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 8.2160e-06 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.9457\n",
      "Epoch 88/100\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 7.1104e-06 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9470\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 6.1158e-06 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9460\n",
      "Epoch 90/100\n",
      "313/313 [==============================] - 12s 40ms/step - loss: 5.2818e-06 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.9464\n",
      "Epoch 91/100\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 4.5680e-06 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.9463\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - 12s 40ms/step - loss: 3.9407e-06 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.9460\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - 12s 40ms/step - loss: 3.3629e-06 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.9464\n",
      "Epoch 94/100\n",
      "313/313 [==============================] - 12s 40ms/step - loss: 2.8962e-06 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9460\n",
      "Epoch 95/100\n",
      "313/313 [==============================] - 12s 40ms/step - loss: 2.4748e-06 - accuracy: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.9466\n",
      "Epoch 96/100\n",
      "313/313 [==============================] - 13s 40ms/step - loss: 2.1294e-06 - accuracy: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.9462\n",
      "Epoch 97/100\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.8180e-06 - accuracy: 1.0000 - val_loss: 0.5045 - val_accuracy: 0.9463\n",
      "Epoch 98/100\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.5537e-06 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.9460\n",
      "Epoch 99/100\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.3334e-06 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.9459\n",
      "Epoch 100/100\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 1.1408e-06 - accuracy: 1.0000 - val_loss: 0.5222 - val_accuracy: 0.9459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21356eb2df0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrainer le model et voir sa precision sur le validation set\n",
    "model.fit(trainX, trainYOH,batch_size=batchSize,epochs=epochs,verbose=1,validation_data=(validX, validYOH))\n",
    "#score = model.evaluate(validX, validYOH, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5221875309944153, 0.945900022983551]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validX, validYOH, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,56,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(19, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 140s 446ms/step - loss: 0.0419 - accuracy: 0.9888 - val_loss: 0.0281 - val_accuracy: 0.9945 - lr: 6.2500e-05\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 161s 515ms/step - loss: 0.0409 - accuracy: 0.9893 - val_loss: 0.0248 - val_accuracy: 0.9948 - lr: 6.2500e-05\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 184s 588ms/step - loss: 0.0408 - accuracy: 0.9888 - val_loss: 0.0257 - val_accuracy: 0.9947 - lr: 6.2500e-05\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 215s 687ms/step - loss: 0.0394 - accuracy: 0.9905 - val_loss: 0.0273 - val_accuracy: 0.9952 - lr: 6.2500e-05\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 227s 727ms/step - loss: 0.0432 - accuracy: 0.9891 - val_loss: 0.0272 - val_accuracy: 0.9946 - lr: 6.2500e-05\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 220s 704ms/step - loss: 0.0420 - accuracy: 0.9895 - val_loss: 0.0263 - val_accuracy: 0.9950 - lr: 6.2500e-05\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9889\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "313/313 [==============================] - 221s 706ms/step - loss: 0.0411 - accuracy: 0.9889 - val_loss: 0.0261 - val_accuracy: 0.9951 - lr: 6.2500e-05\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 223s 712ms/step - loss: 0.0403 - accuracy: 0.9898 - val_loss: 0.0233 - val_accuracy: 0.9955 - lr: 3.1250e-05\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 222s 708ms/step - loss: 0.0436 - accuracy: 0.9889 - val_loss: 0.0251 - val_accuracy: 0.9948 - lr: 3.1250e-05\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 224s 715ms/step - loss: 0.0407 - accuracy: 0.9889 - val_loss: 0.0253 - val_accuracy: 0.9948 - lr: 3.1250e-05\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9891\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "313/313 [==============================] - 223s 713ms/step - loss: 0.0385 - accuracy: 0.9891 - val_loss: 0.0259 - val_accuracy: 0.9947 - lr: 3.1250e-05\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 220s 702ms/step - loss: 0.0387 - accuracy: 0.9892 - val_loss: 0.0248 - val_accuracy: 0.9951 - lr: 1.5625e-05\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 227s 725ms/step - loss: 0.0403 - accuracy: 0.9894 - val_loss: 0.0271 - val_accuracy: 0.9950 - lr: 1.5625e-05\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9890\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "313/313 [==============================] - 222s 709ms/step - loss: 0.0404 - accuracy: 0.9890 - val_loss: 0.0266 - val_accuracy: 0.9952 - lr: 1.5625e-05\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 223s 711ms/step - loss: 0.0372 - accuracy: 0.9897 - val_loss: 0.0249 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 229s 732ms/step - loss: 0.0375 - accuracy: 0.9906 - val_loss: 0.0254 - val_accuracy: 0.9949 - lr: 1.0000e-05\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 237s 757ms/step - loss: 0.0356 - accuracy: 0.9903 - val_loss: 0.0256 - val_accuracy: 0.9949 - lr: 1.0000e-05\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 241s 771ms/step - loss: 0.0385 - accuracy: 0.9901 - val_loss: 0.0251 - val_accuracy: 0.9950 - lr: 1.0000e-05\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 241s 771ms/step - loss: 0.0399 - accuracy: 0.9894 - val_loss: 0.0267 - val_accuracy: 0.9949 - lr: 1.0000e-05\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 242s 775ms/step - loss: 0.0362 - accuracy: 0.9903 - val_loss: 0.0250 - val_accuracy: 0.9952 - lr: 1.0000e-05\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 240s 768ms/step - loss: 0.0377 - accuracy: 0.9908 - val_loss: 0.0266 - val_accuracy: 0.9953 - lr: 1.0000e-05\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 239s 765ms/step - loss: 0.0375 - accuracy: 0.9899 - val_loss: 0.0254 - val_accuracy: 0.9954 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 234s 748ms/step - loss: 0.0369 - accuracy: 0.9905 - val_loss: 0.0252 - val_accuracy: 0.9951 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 234s 748ms/step - loss: 0.0376 - accuracy: 0.9898 - val_loss: 0.0255 - val_accuracy: 0.9952 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 230s 736ms/step - loss: 0.0383 - accuracy: 0.9902 - val_loss: 0.0245 - val_accuracy: 0.9952 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 228s 728ms/step - loss: 0.0365 - accuracy: 0.9902 - val_loss: 0.0249 - val_accuracy: 0.9950 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 286s 914ms/step - loss: 0.0400 - accuracy: 0.9892 - val_loss: 0.0272 - val_accuracy: 0.9953 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 323s 1s/step - loss: 0.0384 - accuracy: 0.9901 - val_loss: 0.0251 - val_accuracy: 0.9950 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 324s 1s/step - loss: 0.0371 - accuracy: 0.9904 - val_loss: 0.0242 - val_accuracy: 0.9947 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 335s 1s/step - loss: 0.0385 - accuracy: 0.9897 - val_loss: 0.0249 - val_accuracy: 0.9949 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 205s 652ms/step - loss: 0.0395 - accuracy: 0.9898 - val_loss: 0.0261 - val_accuracy: 0.9950 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 243s 776ms/step - loss: 0.0372 - accuracy: 0.9901 - val_loss: 0.0254 - val_accuracy: 0.9949 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 244s 778ms/step - loss: 0.0408 - accuracy: 0.9898 - val_loss: 0.0259 - val_accuracy: 0.9952 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 238s 759ms/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.0248 - val_accuracy: 0.9953 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 237s 757ms/step - loss: 0.0362 - accuracy: 0.9908 - val_loss: 0.0260 - val_accuracy: 0.9951 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 238s 760ms/step - loss: 0.0396 - accuracy: 0.9897 - val_loss: 0.0259 - val_accuracy: 0.9951 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 235s 750ms/step - loss: 0.0360 - accuracy: 0.9906 - val_loss: 0.0241 - val_accuracy: 0.9952 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 237s 757ms/step - loss: 0.0361 - accuracy: 0.9905 - val_loss: 0.0253 - val_accuracy: 0.9954 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 234s 747ms/step - loss: 0.0365 - accuracy: 0.9901 - val_loss: 0.0257 - val_accuracy: 0.9949 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 237s 759ms/step - loss: 0.0360 - accuracy: 0.9905 - val_loss: 0.0263 - val_accuracy: 0.9949 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 239s 765ms/step - loss: 0.0386 - accuracy: 0.9898 - val_loss: 0.0261 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 226s 723ms/step - loss: 0.0392 - accuracy: 0.9899 - val_loss: 0.0263 - val_accuracy: 0.9947 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 212s 677ms/step - loss: 0.0392 - accuracy: 0.9901 - val_loss: 0.0250 - val_accuracy: 0.9952 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 212s 676ms/step - loss: 0.0355 - accuracy: 0.9904 - val_loss: 0.0269 - val_accuracy: 0.9949 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 209s 668ms/step - loss: 0.0371 - accuracy: 0.9900 - val_loss: 0.0268 - val_accuracy: 0.9952 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 211s 673ms/step - loss: 0.0373 - accuracy: 0.9902 - val_loss: 0.0273 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 210s 671ms/step - loss: 0.0390 - accuracy: 0.9893 - val_loss: 0.0265 - val_accuracy: 0.9949 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 221s 707ms/step - loss: 0.0394 - accuracy: 0.9904 - val_loss: 0.0260 - val_accuracy: 0.9952 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 226s 721ms/step - loss: 0.0403 - accuracy: 0.9893 - val_loss: 0.0268 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 224s 716ms/step - loss: 0.0367 - accuracy: 0.9895 - val_loss: 0.0258 - val_accuracy: 0.9948 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21360e1a3a0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrainer le model et voir sa precision sur le validation set\n",
    "model.fit(trainX, trainYOH,batch_size=batchSize,epochs=epochs,verbose=1,validation_data=(validX, validYOH),\n",
    "             callbacks=[learning_rate_reduction])\n",
    "#score = model.evaluate(validX, validYOH, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "#Predire les donnees de test\n",
    "newTestData = np.array(testData).reshape(10000,28,56,1)\n",
    "predictions = model.predict(newTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prendre le argmax de chaque rangee\n",
    "predictionsVal = np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer et exporter les prédictions\n",
    "predict = pd.DataFrame([range(10000),predictionsVal], index = ['Index','Class']).transpose()\n",
    "\n",
    "predict.to_csv('predictions_CNN.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05d8f42d34e97b63e1918e352e5e1ee86173089fb3b8c3e567ea1c06d83cd6aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
